{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abeab2b4-d626-4d64-be4b-b0361d167c6a",
   "metadata": {},
   "source": [
    "# Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9ed32-c675-4bd4-a758-f76b9786f9c6",
   "metadata": {},
   "source": [
    "Installed packages needed for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42a24a8b-c0ff-4e0f-aca2-12ebd660b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(httr)\n",
    "library(jsonlite)\n",
    "library(tm)\n",
    "library(wordcloud)\n",
    "library(RColorBrewer)\n",
    "library(SnowballC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895cd234-dd31-4e57-98b0-a8a6d4cb39b7",
   "metadata": {},
   "source": [
    "## Rest API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d7144-37ec-4f0b-9fd1-f3587cc3c414",
   "metadata": {},
   "source": [
    "In this exercise, we aim to fetch data from the Nobel Prize REST API, specifically focusing on the Nobel Prize in Physics for the year 2022. By sending a GET request to the API endpoint, we retrieve the prize information in JSON format. From this data, we will extract the motivations provided for each laureate's award. These motivations explain why the laureates were honored with the prize. We will then preprocess the text by converting it to lowercase, removing punctuation, numbers, common stopwords, and extra whitespace. Finally, we will visualize the most frequent terms from the motivations using a word cloud. This visualization will help us identify key themes in the field of physics research, with the most commonly used words displayed in the word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf07702c-b7e9-4399-a727-2b0e01a2bf9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = input): <text>:8:5: unexpected symbol\n7:     \n8:     motivations_text\n       ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = input): <text>:8:5: unexpected symbol\n7:     \n8:     motivations_text\n       ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "api_url <- \"http://api.nobelprize.org/2.1/nobelPrize/phy/2022\"\n",
    "#API URL for the Nobel Prize in Physics 2022\n",
    "\n",
    "response <- GET(api_url)\n",
    "#Send a GET request to the API to fetch the data\n",
    "\n",
    "if (status_code(response) == 200) {\n",
    "#Check if the API request was successful\n",
    "    \n",
    "    data <- fromJSON(content(response #missing parts\n",
    "                             \n",
    "    \n",
    "    motivations_text <- paste(motivations, collapse = \" \")\n",
    "    \n",
    "\n",
    "    motivation_corpus <- Corpus(VectorSource(motivations_text))\n",
    "    \n",
    "\n",
    "    motivation_corpus <- tm_map(motivation_corpus, content_transformer(tolower))  # Convert to lowercase\n",
    "    motivation_corpus <- tm_map(motivation_corpus, removePunctuation)  \n",
    "                    # Remove punctuation\n",
    "    motivation_corpus <- tm_map(motivation_corpus, removeNumbers)  \n",
    "    # Remove numbers\n",
    "    motivation_corpus <- tm_map(motivation_corpus, removeWords, stopwords(\"english\"))  \n",
    "    # Remove common stopwords\n",
    "    motivation_corpus <- tm_map(motivation_corpus, stripWhitespace)  \n",
    "    # Remove extra whitespace\n",
    "    motivation_corpus <- tm_map(motivation_corpus, stemDocument)  \n",
    "    # Apply stemming to words\n",
    "    motivation_corpus <- tm_map(motivation_corpus, PlainTextDocument)\n",
    "    \n",
    "    wordcloud(\n",
    "        motivation_corpus,\n",
    "        scale = c(5, 0.5),           \n",
    "        #Set min and max scale for word sizes\n",
    "        max.words = 100,             \n",
    "        #Set the maximum number of words\n",
    "        random.order = FALSE,        \n",
    "        #Words will be placed based on frequency\n",
    "        rot.per = 0.35,              \n",
    "        #Percentage of vertical words\n",
    "        use.r.layout = FALSE,        \n",
    "        #Use C++ for word placement\n",
    "        colors = brewer.pal(8, \"Dark2\") \n",
    "    )\n",
    "} else {\n",
    "    print(paste(\"Error: \", status_code(response)))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "733a9724-075d-415f-9b1c-73da7a643115",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url <- \"http://api.nobelprize.org/2.1/nobelPrize/phy/2022\"\n",
    "\n",
    "response <- GET(api_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc8ecf-ca2c-4113-9255-b8916fbd577b",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fbc3b-bca8-478e-a78d-83a578d4d49e",
   "metadata": {},
   "source": [
    "The goal of this part of the assignment is to scrape data from the website https://books.toscrape.com/. We want to create a table that contains key details about the books, specifically the UPC, title, price, and rating, from the first three pages of the site.\n",
    "\n",
    "The code first sets up a URL pattern to get the correct address for each page. Then, it creates an empty table with columns for UPC, title, price, and rating. The program looks at each of the first three pages, gets the book information, and adds it to the table. After the loop finishes, the first five rows of the table are printed, showing only the UPC, title, price, and rating for the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "543548d9-17a0-4cf5-b3ed-f4c218598eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               upc                                 title  price rating\n",
      "1 a897fe39b1053632                  A Light in the Attic £51.77  Three\n",
      "2 90fa61229261140a                    Tipping the Velvet £53.74    One\n",
      "3 6957f44c3847a760                            Soumission £50.10    One\n",
      "4 e00eb4fd7b871a48                         Sharp Objects £47.82   Four\n",
      "5 4165285e1663650f Sapiens: A Brief History of Humankind £54.23   Five\n"
     ]
    }
   ],
   "source": [
    "url_pattern <- \"https://books.toscrape.com/catalogue/page-%s.html\"\n",
    "#The URL pattern for pages, %s acts as a placeholder that will be replaced with the page number\n",
    "\n",
    "books_info <- data.frame(upc = character(), title = character(), price = character(), rating = character(), stringsAsFactors = FALSE)\n",
    "#Empty data frame to store book information\n",
    "\n",
    "for (page_number in 1:3) {\n",
    "  url <- sprintf(url_pattern, page_number)  \n",
    "  page_data <- scrape_books_and_details(url)\n",
    "  books_info <- rbind(books_info, page_data)\n",
    "}\n",
    "#Loop through the three first pages\n",
    "#Scraping the book details and storing it in the table\n",
    "\n",
    "print(head(books_info, n = 5))\n",
    "#Printing the desired table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f176d0c-7542-4537-9f52-c68e51ff960d",
   "metadata": {},
   "source": [
    "As we can see from the table, we have successfully achieved the table format as requested in the homework. The table now includes the correct columns for UPC, title, price, and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a3d439-bb41-4e24-8f50-52428e49de3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
